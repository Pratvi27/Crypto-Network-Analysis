{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Libraries and path variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e824WD2vwc7o",
        "outputId": "c3e46e03-05de-4041-d3a9-388abd0c9179"
      },
      "outputs": [],
      "source": [
        "!pip install cdlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ime4VXB5wefa",
        "outputId": "c18805a0-6a57-4b7c-9eff-b8931019ee48"
      },
      "outputs": [],
      "source": [
        "!pip install karateclub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVwAUSYfhxhj",
        "outputId": "049aaf4d-3a08-49b8-eb04-8026bfcf85eb"
      },
      "outputs": [],
      "source": [
        "!pip install leidenalg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBzopS_qwkxU",
        "outputId": "e0fc9220-de41-405d-f409-b9abfeb5cf88"
      },
      "outputs": [],
      "source": [
        "!pip install wurlitzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXxwmFFhwnFh",
        "outputId": "9fc23ed5-c35a-497a-d360-d0159429dfaa"
      },
      "outputs": [],
      "source": [
        "!pip install ASLPAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdweH6_xhwnm",
        "outputId": "15265392-ddbe-4bd0-987e-26ef1e64b53c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "import shutil\n",
        "\n",
        "import networkx.algorithms.community as nx_comm\n",
        "import itertools\n",
        "from cdlib import algorithms\n",
        "import networkx as nx\n",
        "\n",
        "returns_filepath = '/content/drive/Shareddrives/BTP/CombinedFiles/returns_after_interpolation.xlsx'\n",
        "closing_price_filepath = '/content/drive/Shareddrives/BTP/CombinedFiles/closing_price_crypto_stocks_after_interpolation.xlsx'  \n",
        "folderpath = '/content/drive/Shareddrives/BTP/FinalNetworks/SlidingWindow/Network'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J38209-eslup"
      },
      "outputs": [],
      "source": [
        "# Get graph\n",
        "def get_adjacency_matrix(corrMatrix, n, threshold=0.3):\n",
        "  adj_matrix = [[0 for _ in range(n)] for _ in range(n)]\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if i!=j and np.abs(corrMatrix[i][j])>threshold:\n",
        "        adj_matrix[i][j] = corrMatrix[i][j]\n",
        "      \n",
        "  return nx.from_numpy_matrix(np.matrix(adj_matrix))\n",
        "\n",
        "\n",
        "# Timespan in num of days\n",
        "def get_interval_data(start_idx, timespan, data):\n",
        "  col_list = []\n",
        "  for cols in data.columns:\n",
        "    if pd.notnull(data[cols][start_idx]):\n",
        "      col_list.append(cols)\n",
        "  \n",
        "  df = data[col_list][start_idx:start_idx+timespan].copy().reset_index().drop(columns=['index'])\n",
        "  return df\n",
        "\n",
        "# Generate metrics\n",
        "def get_metrics(G, filename, avg_weight, timespan, pedge):\n",
        "  avg_neighbour_degree = []\n",
        "  degree = G.degree()\n",
        "  avg_neighbour_degree = nx.average_neighbor_degree(G)\n",
        "  degree_centrality_nodes = nx.degree_centrality(G)\n",
        "  eigen_vector_centrality_nodes = nx.eigenvector_centrality(G, max_iter=200)\n",
        "  katz_centrality_nodes = nx.katz_centrality_numpy(G)\n",
        "  closeness_centrality_nodes = nx.closeness_centrality(G)\n",
        "  betweenness_centrality_nodes = nx.betweenness_centrality(G)\n",
        "  clustering_array = nx.clustering(G)\n",
        "  arr = []\n",
        "  for node in G.nodes():\n",
        "    arr.append([node, degree[node], avg_neighbour_degree[node], degree_centrality_nodes[node], eigen_vector_centrality_nodes[node], katz_centrality_nodes[node], closeness_centrality_nodes[node], betweenness_centrality_nodes[node], clustering_array[node]])\n",
        "  pd.DataFrame(arr, columns = ['Coin','Degree','AvgNeighbourDegree','DegreeC','EigenVectorC','KatzC','ClosenessC','BetweennessC','ClusteringCoef']).to_excel(filename+'.xlsx',index=False)\n",
        "\n",
        "  \n",
        "  G_deg = nx.degree_histogram(G)\n",
        "  G_deg_sum = [a * b for a, b in zip(G_deg, range(0, len(G_deg)))]\n",
        "  network_metrics = []\n",
        "  print(filename.split('/')[-1].split('_')[-1])\n",
        "  network_metrics.append(timespan)\n",
        "  network_metrics.append(filename.split('/')[-1].split('_')[-1])\n",
        "  network_metrics.append(len(G.nodes()))\n",
        "  network_metrics.append(len(G.edges()))\n",
        "  network_metrics.append(nx.average_clustering(G))\n",
        "  network_metrics.append(sum(G_deg_sum)/G.number_of_nodes())\n",
        "  network_metrics.append(nx.number_connected_components(G))\n",
        "  \n",
        "  # If the graph is not connected then calculate metrics for the largest sub-graph \n",
        "  if nx.is_connected(G):\n",
        "    network_metrics.append(nx.average_shortest_path_length(G))\n",
        "    network_metrics.append(nx.radius(G))\n",
        "    network_metrics.append(nx.diameter(G))\n",
        "    network_metrics.append(nx.periphery(G))\n",
        "    network_metrics.append(nx.center(G))\n",
        "  else:\n",
        "    network_metrics.append(nx.average_shortest_path_length(G.subgraph(max(nx.connected_components(G), key=len))))\n",
        "    network_metrics.append(nx.radius(G.subgraph(max(nx.connected_components(G), key=len))))\n",
        "    network_metrics.append(nx.diameter(G.subgraph(max(nx.connected_components(G), key=len))))\n",
        "    network_metrics.append(nx.periphery(G.subgraph(max(nx.connected_components(G), key=len))))\n",
        "    network_metrics.append(nx.center(G.subgraph(max(nx.connected_components(G), key=len))))\n",
        "  \n",
        "\n",
        "  network_metrics.append(nx.transitivity(G))\n",
        "  network_metrics.append(nx.density(G))\n",
        "  network_metrics.append(nx.degree_assortativity_coefficient(G))\n",
        "  network_metrics.append(avg_weight)\n",
        "  rc = nx.rich_club_coefficient(G, normalized=False, seed=42)\n",
        "  network_metrics.append(np.round(np.mean(list(rc.values())),4))\n",
        "  network_metrics.append(pedge)\n",
        "  network_metrics.append(len(G.edges()) - pedge)\n",
        "\n",
        "  # Core-expansion (Overlapping communities)\n",
        "  coms = algorithms.core_expansion(G)\n",
        "  temp = coms.communities\n",
        "  network_metrics.append(temp)\n",
        "\n",
        "  # Leiden \n",
        "  coms = algorithms.leiden(G)\n",
        "  temp = coms.communities\n",
        "  network_metrics.append(temp)\n",
        "  network_metrics.append(nx_comm.modularity(G,communities = temp))\n",
        "\n",
        "  network_metrics.append(nx.dominating_set(G))\n",
        "  \n",
        "  return network_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3chBsMLAtAEe"
      },
      "outputs": [],
      "source": [
        "def get_all_metrics(timespan, increment, start_idx, end_idx, dates_arr, data, folderpath,threshold=0.3):\n",
        "  net_metrics = []\n",
        "  count =0\n",
        "  ans=[]\n",
        "  \n",
        "  if not os.path.exists(folderpath+'/EdgeList'):\n",
        "    os.mkdir(folderpath+'/EdgeList')\n",
        "    os.mkdir(folderpath+'/NodeMetrics')\n",
        "  \n",
        "  for i in range(start_idx,end_idx,increment):\n",
        "    count=0\n",
        "\n",
        "    # change it to <=end_idx if no network required after end_idx\n",
        "    if (i+timespan)<=len(data):\n",
        "      temp = get_interval_data(i, timespan, data)\n",
        "      node1 = []\n",
        "      node2 = []\n",
        "      weight = []\n",
        "      corr_matrix = np.corrcoef(temp.T)\n",
        "      \n",
        "      ans.append([np.mean(corr_matrix), np.var(corr_matrix)])\n",
        "      crypto_list = temp.columns\n",
        "      G = get_adjacency_matrix(corr_matrix, len(crypto_list), threshold)\n",
        "      \n",
        "      for line in nx.generate_edgelist(G, data=[\"weight\"]):\n",
        "        line_data = line.split(' ')\n",
        "        node1.append(crypto_list[int(line_data[0])])\n",
        "        node2.append(crypto_list[int(line_data[1])])\n",
        "        weight.append(np.round(float(line_data[2]),2))\n",
        "        if float(line_data[2])>float(0):\n",
        "          count+=1\n",
        "      data_temp = pd.DataFrame(np.transpose([node1,node2,weight]), columns=['Node1','Node2','Weight'])\n",
        "      data_temp.to_excel(folderpath + '/EdgeList/'+dates_arr[i+1]+'.xlsx', index=False)\n",
        "      \n",
        "      graph = nx.Graph()\n",
        "      weight = []\n",
        "      for index,row in data_temp.iterrows():\n",
        "          graph.add_edges_from([(row['Node1'],row['Node2'])],weight = float(row['Weight']))\n",
        "          weight.append(float(row['Weight']))\n",
        "      net_metrics.append(get_metrics(graph,folderpath + '/NodeMetrics/'+ dates_arr[i+1], np.mean(weight), timespan,count))\n",
        "      \n",
        "  df_new = pd.DataFrame(net_metrics, columns=['Time','File','#Nodes','#Edges','AvgClustering','AvgDegree','ConnectedComponents','CharacteristicPathLength','Radius','Diameter','Periphery','Centers','Transitivity','Density','Assortivity','AvgCorr','RCC','PEdges','Diff','core-expansion','Leiden','LeidenM','Walktrap','WalktrapM','dominating_set'])\n",
        "  df_new.to_excel(folderpath + '/MasterFile_'+str(int(threshold*10))+'_'+str(timespan)+'_' +str(increment) + '.xlsx',index=False)\n",
        "  return df_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Driver steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbKE9bDXA734",
        "outputId": "276a5666-17a2-45cf-e9a7-3bab8c7430b6"
      },
      "outputs": [],
      "source": [
        "# returns file\n",
        "data = pd.read_excel(returns_filepath)\n",
        "\n",
        "# dates of closing price\n",
        "dates_arr = pd.read_excel(closing_price_filepath)['Date']\n",
        "dates_arr = [dates_arr[i].split(' ')[0] for i in range(len(dates_arr))]\n",
        "start_date = '2017-08-08'\n",
        "\n",
        "# segment size for correlation network\n",
        "timespan = 14\n",
        "\n",
        "# inc =  (timespan) for moving window\n",
        "increment = 1\n",
        "\n",
        "# if you want data for 8th aug give date of 7th aug\n",
        "start_index = list(dates_arr).index(start_date)\n",
        "\n",
        "# last index to possibly start the network\n",
        "# if end_index=14 then network from 13-20 index is also considered since 13<end_index\n",
        "end_index = len(data)\n",
        "\n",
        "# comment else part to add files without deleting the existing subdirectories\n",
        "if not os.path.exists(folderpath):\n",
        "  os.mkdir(folderpath)\n",
        "else:\n",
        "  shutil.rmtree(folderpath)# Removes all the subdirectories\n",
        "  os.mkdir(folderpath)\n",
        "\n",
        "df = get_all_metrics(timespan, increment, start_index, end_index, dates_arr, data, folderpath+'/')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "E86QqcEoiy2H",
        "fWt17smc1a_T",
        "KqZyh40rA46X",
        "tiPaQajSA96L",
        "3qhW95odlK9n",
        "Qq2asSYB_NRs",
        "dITzrPTc_KcC",
        "rpxnCRw38KRq",
        "djzb8zdkiLD8",
        "Le9Sh-UF3Ueq",
        "40ax4_gHJAn8",
        "4BAUFl46kUh7",
        "DSWKwWYPlIa5"
      ],
      "name": "Pipeline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
